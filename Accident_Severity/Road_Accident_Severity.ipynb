{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Road Accident Severity Analysis**\n",
        "This notebook demonstrates the implementation of various machine learning models to predict road accident severity."
      ],
      "metadata": {
        "id": "VvW-rSCPuRYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Installation\n",
        "First, let's install the required packages:"
      ],
      "metadata": {
        "id": "iUoCLaCBucQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnRZxGexuLcd"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install imbalanced-learn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "TkRRCiq2uwBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LFTi9UbVuz0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n",
        "Load the Dataset"
      ],
      "metadata": {
        "id": "x2CusG2Xu2KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the dataset to Colab (you'll need to upload RTADatasetE1.csv to your Colab environment)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the uploaded file\n",
        "df = pd.read_csv(\"RTADatasetE1.csv\")"
      ],
      "metadata": {
        "id": "fmvcyyc5u7K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Time Feature"
      ],
      "metadata": {
        "id": "3V2Y5wGTu__v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Time' column to datetime format and extract hour\n",
        "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S')\n",
        "df['Hour'] = df['Time'].dt.hour"
      ],
      "metadata": {
        "id": "LyyLrkNLvDWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Encoding"
      ],
      "metadata": {
        "id": "UZWlWR1AvFxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Day of week encoding\n",
        "day_map = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3,\n",
        "           'Friday': 4, 'Saturday': 5, 'Sunday': 6, 'NA': -1}\n",
        "df['Day_of_week'] = df['Day_of_week'].map(day_map)\n",
        "\n",
        "# Age band encoding\n",
        "age_map = {'Under 18': 0, '18-30': 1, '31-50': 2, 'Above 50': 3, 'NA': -1}\n",
        "df['Age_band_of_driver'] = df['Age_band_of_driver'].map(age_map)\n",
        "df['Age_band_of_casualty'] = df['Age_band_of_casualty'].map(age_map)\n",
        "\n",
        "# Sex encoding using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Sex_of_driver'] = le.fit_transform(df['Sex_of_driver'])\n",
        "df['Sex_of_casualty'] = le.fit_transform(df['Sex_of_casualty'])\n",
        "\n",
        "# Education level encoding\n",
        "edu_map = {'Elementary school': 0, 'Junior high school': 1, 'High school': 2,\n",
        "           'College': 3, 'Illiterate': -1, 'Writing & reading': -1}\n",
        "df['Educational_level'] = df['Educational_level'].map(edu_map)\n",
        "\n",
        "# Vehicle driver relation encoding\n",
        "vdr_map = {'Employee': 1, 'Owner': 0, 'Unknown': -1, 'Other': 3}\n",
        "df['Vehicle_driver_relation'] = df['Vehicle_driver_relation'].map(vdr_map)\n",
        "\n",
        "# Add all other encoding mappings here (continuing with the same pattern)\n",
        "# [Note: For brevity, I'm showing a subset of the encodings.\n",
        "#  Include all other mappings from the original code]"
      ],
      "metadata": {
        "id": "NrzfevEkvNcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "0Zobu8R0vPaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and target\n",
        "X = df.drop(['Time', 'Accident_severity'], axis=1)\n",
        "y = df['Accident_severity']\n",
        "\n",
        "# Remove columns with missing data\n",
        "X = X.dropna(axis=1, how='any')\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Handle imbalanced data using SMOTE\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "ioOqgA2yvTyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation\n",
        "Histogram-based Gradient Boosting"
      ],
      "metadata": {
        "id": "3gRfhRRnvV2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HGB Model\n",
        "hgb_params = {\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'max_iter': [100, 200, 300]\n",
        "}\n",
        "hgb_model = GridSearchCV(HistGradientBoostingClassifier(), hgb_params, cv=5)\n",
        "hgb_model.fit(X_train, y_train)\n",
        "hgb_pred = hgb_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "hgb_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, hgb_pred),\n",
        "    'precision': precision_score(y_test, hgb_pred, average='macro'),\n",
        "    'recall': recall_score(y_test, hgb_pred, average='macro'),\n",
        "    'f1': f1_score(y_test, hgb_pred, average='macro')\n",
        "}\n",
        "\n",
        "print(\"HGB Model Metrics:\")\n",
        "for metric, value in hgb_metrics.items():\n",
        "    print(f\"{metric.capitalize()}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "e15h381kvdKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "VPZ6Uit9vgun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RF Model\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "rf_model = GridSearchCV(RandomForestClassifier(), rf_params, cv=5)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "rf_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, rf_pred),\n",
        "    'precision': precision_score(y_test, rf_pred, average='macro'),\n",
        "    'recall': recall_score(y_test, rf_pred, average='macro'),\n",
        "    'f1': f1_score(y_test, rf_pred, average='macro')\n",
        "}\n",
        "\n",
        "print(\"\\nRF Model Metrics:\")\n",
        "for metric, value in rf_metrics.items():\n",
        "    print(f\"{metric.capitalize()}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "qk-8jfljvh-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine"
      ],
      "metadata": {
        "id": "vlFshEmFvmaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM Model\n",
        "svm_params = {\n",
        "    'C': [1, 10, 100],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "svm_model = GridSearchCV(SVC(), svm_params, cv=5)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "svm_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, svm_pred),\n",
        "    'precision': precision_score(y_test, svm_pred, average='macro'),\n",
        "    'recall': recall_score(y_test, svm_pred, average='macro'),\n",
        "    'f1': f1_score(y_test, svm_pred, average='macro')\n",
        "}\n",
        "\n",
        "print(\"\\nSVM Model Metrics:\")\n",
        "for metric, value in svm_metrics.items():\n",
        "    print(f\"{metric.capitalize()}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "eW5PJ8-bvoDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "F5TqVhVRvqEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model\n",
        "knn_params = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "knn_model = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "knn_metrics = {\n",
        "    'accuracy': accuracy_score(y_test, knn_pred),\n",
        "    'precision': precision_score(y_test, knn_pred, average='macro'),\n",
        "    'recall': recall_score(y_test, knn_pred, average='macro'),\n",
        "    'f1': f1_score(y_test, knn_pred, average='macro')\n",
        "}\n",
        "\n",
        "print(\"\\nKNN Model Metrics:\")\n",
        "for metric, value in knn_metrics.items():\n",
        "    print(f\"{metric.capitalize()}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "NlyrpdOOvr73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Functions"
      ],
      "metadata": {
        "id": "8oVj-u1Ivtwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bar_graph(metric, values, algorithms):\n",
        "    \"\"\"\n",
        "    Plot bar graph comparing model performances\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(algorithms, values, color='lightblue', edgecolor='black')\n",
        "    max_index = values.index(max(values))\n",
        "    bars[max_index].set_edgecolor('red')\n",
        "    plt.xlabel('Algorithms')\n",
        "    plt.ylabel(metric)\n",
        "    plt.title(f'{metric} of Different Algorithms')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(conf_matrix, title):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix heatmap\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "X2ZvrJ4FvwWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for plotting\n",
        "algorithms = ['HGB', 'RF', 'SVM', 'KNN']\n",
        "metrics = {\n",
        "    'Precision': [m['precision'] for m in [hgb_metrics, rf_metrics, svm_metrics, knn_metrics]],\n",
        "    'Accuracy': [m['accuracy'] for m in [hgb_metrics, rf_metrics, svm_metrics, knn_metrics]],\n",
        "    'F1-score': [m['f1'] for m in [hgb_metrics, rf_metrics, svm_metrics, knn_metrics]],\n",
        "    'Recall': [m['recall'] for m in [hgb_metrics, rf_metrics, svm_metrics, knn_metrics]]\n",
        "}\n",
        "\n",
        "# Plot performance metrics\n",
        "for metric, values in metrics.items():\n",
        "    plot_bar_graph(metric, values, algorithms)\n",
        "\n",
        "# Plot confusion matrices\n",
        "confusion_matrices = {\n",
        "    'HGB': confusion_matrix(y_test, hgb_pred),\n",
        "    'RF': confusion_matrix(y_test, rf_pred),\n",
        "    'SVM': confusion_matrix(y_test, svm_pred),\n",
        "    'KNN': confusion_matrix(y_test, knn_pred)\n",
        "}\n",
        "\n",
        "for name, matrix in confusion_matrices.items():\n",
        "    plot_confusion_matrix(matrix, f'{name} Confusion Matrix')"
      ],
      "metadata": {
        "id": "siQ4f-mevyyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Models (Optional)"
      ],
      "metadata": {
        "id": "6PavMkiyv1qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best performing model (assuming it's the Random Forest)\n",
        "joblib.dump(rf_model, 'best_model.joblib')\n",
        "\n",
        "# To load the model later:\n",
        "# loaded_model = joblib.load('best_model.joblib')"
      ],
      "metadata": {
        "id": "tQnMzbzUv4nM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}